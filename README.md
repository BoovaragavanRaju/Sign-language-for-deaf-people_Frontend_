# âœ‹ Sign Language for Deaf People â€“ Frontend

A web-based interface that translates sign language gestures into text, enabling seamless communication between deaf individuals and others.
## ğŸŒŸ Features
- ğŸ¥ Real-time gesture input via webcam
- ğŸ§  Integration with ML-based gesture recognition API
- ğŸ’¬ Instant text translation display
- ğŸ“± Responsive design for mobile and desktop
- ğŸ¨ Clean and accessible UI built with HTML, CSS, and JavaScript

## ğŸ§° Tech Stack
- **Frontend:** HTML5, CSS3, JavaScript
- **Backend (API):** Python Flask / TensorFlow (connected via REST API)
- **Version Control:** Git & GitHub
- **Tools:** VS Code, Google Teachable Machine / MediaPipe

## ğŸ—ï¸ Architecture
The frontend sends video frame data to the backend ML model through REST endpoints. The backend processes gestures and returns the translated text, which is dynamically rendered on the UI.

## âš™ï¸ Installation
```bash
# Clone the repository
git clone https://github.com/BoovaragavanRaju/SignLanguageTranslator-Frontend.git

# Navigate to the project folder
cd SignLanguageTranslator-Frontend

# Open index.html in your browser
